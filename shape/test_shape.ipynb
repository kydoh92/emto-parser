{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import utils as ut\n",
    "from utils import flush\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(f):\n",
    "    string = f.readline()\n",
    "    JOBNAM = string[10:20].strip()\n",
    "    MSGL =  int(string[27:30])\n",
    "    return JOBNAM, MSGL\n",
    "def L3(f):\n",
    "    string = f.readline()\n",
    "    FOR001 = string[7:].strip()\n",
    "    return FOR001\n",
    "def L6(f):\n",
    "    string = f.readline()\n",
    "    Lmax = int(string[7:11])\n",
    "    NSR = int(string[17:21])\n",
    "    NFI = int(string[27:30])\n",
    "    return Lmax, NSR, NFI\n",
    "def L7(f):\n",
    "    string = f.readline()\n",
    "    NPRN = int(string[7:11])\n",
    "    IVEF = int(string[17:21])\n",
    "    return NPRN, IVEF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"lat_bcc.dat\"\n",
    "with open(filename) as f:\n",
    "    flush(f)\n",
    "    JOBNAM, MSGL = L2(f)\n",
    "    # print(JOBNAM, MSGL)\n",
    "    FOR001 = L3(f)\n",
    "    # print(FOR001)\n",
    "    flush(f,2)\n",
    "    Lmax, NSR, NFI = L6(f)\n",
    "    NPRN, IVEF = L7(f)\n",
    "    # print(Lmax, NSR, NFI, NPRN, IVEF)\n",
    "    \n",
    "# Combine entities\n",
    "Input = {\n",
    "    'Meta':{\n",
    "        'JOBNAM': [JOBNAM, None],\n",
    "        'MSGL': [MSGL, None],\n",
    "        'FOR001': [FOR001, None],\n",
    "        'NPRN': [NPRN, None],\n",
    "    },\n",
    "    'Approximation':{\n",
    "        'Lmax': [Lmax, None],\n",
    "        'NSR': [NSR, None],\n",
    "        'NFI': [NFI, None],\n",
    "        'IVEF': [IVEF, None]\n",
    "    }\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Meta': {'JOBNAM': ['lat_bcc', None],\n",
       "  'MSGL': [1, None],\n",
       "  'FOR001': ['../../kstr/lat_bcc/smx/lat_bcc.tfh', None],\n",
       "  'NPRN': [0, None]},\n",
       " 'Approximation': {'Lmax': [30, None],\n",
       "  'NSR': [129, None],\n",
       "  'NFI': [11, None],\n",
       "  'IVEF': [3, None]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {}\n",
    "with open(\"lat_bcc.dat\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        match = re.search(r\"(\\w+)\\.=([\\w\\/\\.]+)\", line)\n",
    "        if match:\n",
    "            key, value = match.groups()\n",
    "            try:\n",
    "                # Try to convert numerical values to integers\n",
    "                value = int(value)\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    # Try to convert numerical values to floats\n",
    "                    value = float(value)\n",
    "                except ValueError:\n",
    "                    pass  # If not a number, keep the value as string\n",
    "            data[key] = value\n",
    "\n",
    "with open('database.json', 'w') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FHNDLR1(f):\n",
    "    # read time\n",
    "    timestamp = ut.head_timestamp(f)\n",
    "    return timestamp\n",
    "def FHNDLR2(f):\n",
    "    # read FOR001\n",
    "    FOR001 = ut.css(f)\n",
    "    # flush 2 lines (FOR002, FOOR006)\n",
    "    flush(f,2)\n",
    "    return FOR001\n",
    "def FHNDLR3(f):\n",
    "    # read system information\n",
    "    EMTO = ut.css(f)\n",
    "    branch = ut.css(f)\n",
    "    hash_key = ut.css(f)\n",
    "    compile_on = ut.css(f)\n",
    "    OS = ut.css(f)\n",
    "    CPU = ut.css(f)\n",
    "    compiler = ut.css(f)\n",
    "    library = ut.css(f)\n",
    "    return EMTO, branch, hash_key, compile_on, OS, CPU, compiler, library\n",
    "def INPUT(f):\n",
    "    # NSR, LMAX, NFI, IVEF\n",
    "    NSR, LMAX, NFI, IVEF = ut.getint(f)\n",
    "    return NSR, LMAX, NFI, IVEF\n",
    "def TRNSFM(f):\n",
    "    # slope_matrices, KW2\n",
    "    string = f.readline()\n",
    "    slope_matrices = string[26:36].strip()\n",
    "    KW2 = float(string[50:60])\n",
    "    return slope_matrices, KW2\n",
    "def BLATTS(f):\n",
    "    # format {plane_num: 1, plane_info:[x,y,z,d], point_num: 6, point_info:[[x,y,z,d(상대값)],...]}\n",
    "    site_info = []\n",
    "    while 1:\n",
    "        string = f.readline()\n",
    "        # strip first line\n",
    "        if \"V(tetra)\" in string:\n",
    "            print(string)\n",
    "            site_info.append(plane_info)\n",
    "            v_info = {}\n",
    "            str_list = ut.getstring_withoutequal(f, string)\n",
    "            float_list = ut.getfloat(f, string)\n",
    "            v_info[str_list[0]] = float_list[0]\n",
    "            v_info[str_list[1]] = float_list[1]\n",
    "            site_info.append(v_info)\n",
    "            break\n",
    "        elif len(string.split()) == 6:\n",
    "            try:\n",
    "                site_info.append(plane_info)\n",
    "            except:\n",
    "                pass\n",
    "            plane_info = {}\n",
    "            point_info = []\n",
    "            str_list = string.split()\n",
    "            plane_info['plane_num'] = int(str_list[0])\n",
    "            plane_info['plane_info'] = [float(str_list[1]), float(str_list[2]), float(str_list[3]), float(str_list[4])]\n",
    "            plane_info['point_num'] = int(str_list[5])\n",
    "            \n",
    "        elif len(string.split()) == 4:\n",
    "            point_info.append([float(string.split()[0]), float(string.split()[1]), float(string.split()[2]), float(string.split()[3])])\n",
    "            plane_info['point_info'] = point_info\n",
    "            \n",
    "    return site_info\n",
    "\n",
    "def RMESH(f):\n",
    "    # format {NINT: 4, RINT: [1,1,1,1], NSRI: [1,1,1], DSRI: [1,1,1]}\n",
    "    rmesh_dict = {}\n",
    "    rmesh_dict['NINT'] = ut.getint(f)[0]\n",
    "    \n",
    "    temp_list = []\n",
    "    for i in range(rmesh_dict['NINT']):\n",
    "        temp_list.append(ut.e1f(f))\n",
    "    rmesh_dict['RINT'] = temp_list    \n",
    "    \n",
    "    temp_list1 = [] # for NSRI\n",
    "    temp_list2 = [] # for DSRI\n",
    "    for i in range(rmesh_dict['NINT']-1):\n",
    "        sri_list = ut.getfloat(f)\n",
    "        temp_list1.append(int(sri_list[1]))\n",
    "        temp_list2.append(sri_list[3])\n",
    "    rmesh_dict['NSRI'] = temp_list1\n",
    "    rmesh_dict['DSRI'] = temp_list2\n",
    "    return rmesh_dict\n",
    "    \n",
    "def SETROT(f):\n",
    "    # format 2\n",
    "    setrot = ut.getint(f)[0]\n",
    "    return setrot\n",
    "    \n",
    "def UPDATE(f):\n",
    "    # format {l:[1,1,1,], d(l): [1,1,1,], D(l): [1,1,1,], %: [1,1,1,1]}\n",
    "    flush(f,2)\n",
    "    l_list = []; dl_list = []; Dl_list = []; percent_list = []\n",
    "    for i in range(int(LMAX) + 1):\n",
    "        temp_list = ut.getfloat(f)\n",
    "        l_list.append(int(temp_list[0]))\n",
    "        dl_list.append(temp_list[1])\n",
    "        Dl_list.append(temp_list[2])\n",
    "        percent_list.append(temp_list[3])\n",
    "    update_dict = {'l':l_list, 'd(l)':dl_list, 'D(l)':Dl_list, '%':percent_list}\n",
    "    return update_dict\n",
    "\n",
    "def SITES_INFO(f):\n",
    "    sites = []\n",
    "    while 1:\n",
    "        site_info = {}\n",
    "        # site num\n",
    "        try:\n",
    "            site_num_line = f.readline()\n",
    "        except:\n",
    "            print(\"No more site information\"); break\n",
    "            \n",
    "        if \"Site number\" not in site_num_line:\n",
    "            print(\"No more site information\"); break\n",
    "        token = site_num_line.split(': ')\n",
    "        site_num = int(token[1].strip())\n",
    "        \n",
    "        # BLATTS\n",
    "        Si, WSA, SC = ut.getfloat(f)\n",
    "        NSC, NVN = ut.getint(f)\n",
    "        blatts = BLATTS(f)\n",
    "        RSORT = ut.colonspacestring(f)\n",
    "        rmesh = RMESH(f)\n",
    "        setrot = SETROT(f)\n",
    "        update = UPDATE(f)\n",
    "        NVSF = int(ut.css(f))\n",
    "        SIGMA_01 = ut.e1f(f)\n",
    "        SIGMA_0NSR = ut.e1f(f)\n",
    "        flush(f) # Volume 지우기\n",
    "        VOL_INSCRIBED = ut.getfloat(f)[0]\n",
    "        VOL_INTEGRATED = ut.getfloat(f)[0]\n",
    "        VOL_SUMMED = ut.getfloat(f)[0]\n",
    "        VOL_EXACT = ut.getfloat(f)[0]\n",
    "        ERROR = ut.getfloat(f)[0]\n",
    "        \n",
    "        # 데이터 dict에 넣기\n",
    "        site_info['site_num'] = site_num\n",
    "        site_info['Si'] = Si; site_info['WSA'] = WSA; site_info['SC'] = SC\n",
    "        site_info['NSC'] = NSC; site_info['NVN'] = NVN\n",
    "        site_info['BLATTS'] = blatts; site_info['RSORT'] = RSORT\n",
    "        site_info['RMESH'] = rmesh; site_info['SETROT'] = setrot\n",
    "        site_info['UPDATE'] = update; site_info['NVSF'] = NVSF\n",
    "        site_info['SIGMA_01'] = SIGMA_01; site_info['SIGMA_0NSR'] = SIGMA_0NSR\n",
    "        site_info['VOL_INSCRIBED'] = VOL_INSCRIBED; site_info['VOL_INTEGRATED'] = VOL_INTEGRATED\n",
    "        site_info['VOL_SUMMED'] = VOL_SUMMED; site_info['VOL_EXACT'] = VOL_EXACT\n",
    "        site_info['ERROR'] = ERROR\n",
    "        \n",
    "        sites.append(site_info)\n",
    "    return sites    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           V(tetra) =  0.50000000  V(atom)  =  0.50000000\n",
      "\n",
      "No more site information\n"
     ]
    }
   ],
   "source": [
    "filename=\"lat_bcc.prn\"\n",
    "### 빈줄 제거\n",
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line for line in lines if line.strip()]\n",
    "with open('temp_'+filename, 'w') as f:\n",
    "    f.writelines(lines)\n",
    "    \n",
    "### 데이터 읽기\n",
    "with open('temp_'+filename, 'r') as f:\n",
    "    # FHNDLR\n",
    "    time_start = FHNDLR1(f)\n",
    "    FOR001 = FHNDLR2(f)\n",
    "    EMTO, branch, hash_key, compile_on, OS, CPU, compiler, library = FHNDLR3(f)\n",
    "        \n",
    "    # print(time_start, FOR001, EMTO, branch, hash_key, compile_on, OS, CPU, compiler, library)\n",
    "    \n",
    "    NSR, LMAX, NFI, IVEF = INPUT(f)\n",
    "    slope_matrices, KW2 = TRNSFM(f)\n",
    "    # print(NSR, LMAX, NFI, IVEF, slope_matrices, KW2)\n",
    "    \n",
    "    site_info = SITES_INFO(f)\n",
    "    # print(site_info)\n",
    "    \n",
    "# Combine entities\n",
    "Output = {\n",
    "    'FHNDLR': {\n",
    "        'time_start': [time_start, None],\n",
    "        'FOR001': [FOR001, None],\n",
    "        'EMTO': [EMTO, None],\n",
    "        'branch': [branch, None],\n",
    "        'hash_key': [hash_key, None],\n",
    "        'compile_on': [compile_on, None],\n",
    "        'OS': [OS, None],\n",
    "        'CPU': [CPU, None],\n",
    "        'compiler': [compiler, None],\n",
    "        'library': [library, None]\n",
    "    },\n",
    "    'INPUT': {\n",
    "        'NSR': [NSR, None],\n",
    "        'LMAX': [LMAX, None],\n",
    "        'NFI': [NFI, None],\n",
    "        'IVEF': [IVEF, None]\n",
    "    },\n",
    "    'TRNSFM': {\n",
    "        'slope_matrices': [slope_matrices, None],\n",
    "        'KW2': [KW2, None]\n",
    "    },\n",
    "    'SITES_INFO': site_info\n",
    "}\n",
    "\n",
    "with open('output.json', 'w') as f:\n",
    "    json.dump(Output, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 71.0, 1.0, 0.00095696]\n",
      "['NSRI(', 'DSRI(']\n",
      "['NSRI(', 'DSRI(']\n",
      "['NSRI(', 'DSRI(']\n",
      "['NSRI(', '1)=', 'DSRI(', '1)=']\n",
      "['   ', '  0']\n"
     ]
    }
   ],
   "source": [
    "# string = 'INPUT     NSR =  129 LMAX=   30 NFI =   11 IVEF=    3'\n",
    "string = 'NSRI( 1)=          71 DSRI( 1)=  0.00095696'\n",
    "# string = 'A     =  1.000000 B     =  1.000000 C     =  1.000000'\n",
    "float_list = [float(s) for s in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", string)]\n",
    "str_list = [s for s in string.split() if not re.match(r\"[-+]?\\d*\\.\\d+|\\d+\", s)]\n",
    "res = [s for s in string.split() if not s.replace('.','',1).isdigit()]\n",
    "# 해당 list에서 '=' 또는 ':' 제거 하기\n",
    "str_list_2 = [s for s in str_list if s != '=' and s != ':']\n",
    "str_list_3 = [s.replace('=','') for s in str_list_2]\n",
    "token = string.split('=')[1:3]\n",
    "str_list_4 = list(map(lambda x:x[:3],token))\n",
    "# str_list = re.split('=|\\s', string)\n",
    "# print(str_list)\n",
    "# int_list = [int(s) for s in str_list if s.isdigit()]\n",
    "# print(int_list)\n",
    "print(float_list)\n",
    "print(str_list)\n",
    "print(str_list_2)\n",
    "print(str_list_3)\n",
    "print(res)\n",
    "print(str_list_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyemto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
